{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTEbIgfWczbZRUwzXOWOHE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bidishaaiml/COE_week12/blob/main/movie_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Python program to analyze the sentiment of movie reviews.**"
      ],
      "metadata": {
        "id": "eR7X19l5cnPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_knQ3YPsaBDz",
        "outputId": "d43bec6f-3c27-45c9-ae3b-7fa85f78f2fa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkQPXNhXZ9eY",
        "outputId": "f0451724-6216-4167-bdc1-b62ee26e801d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review 1:\n",
            "Text: The movie was fantastic! The plot was gripping and the characters were well-developed.\n",
            "Sentiment: Positive\n",
            "Polarity: 0.5, Subjectivity: 0.95\n",
            "\n",
            "Review 2:\n",
            "Text: I didn't like the movie at all. It was too slow and the acting was poor.\n",
            "Sentiment: Negative\n",
            "Polarity: -0.23333333333333336, Subjectivity: 0.3333333333333333\n",
            "\n",
            "Review 3:\n",
            "Text: It was an average movie, nothing special but not bad either.\n",
            "Sentiment: Positive\n",
            "Polarity: 0.1857142857142857, Subjectivity: 0.546031746031746\n",
            "\n",
            "Review 4:\n",
            "Text: Absolutely terrible! I wasted two hours of my life.\n",
            "Sentiment: Negative\n",
            "Polarity: -0.6, Subjectivity: 0.5\n",
            "\n",
            "Review 5:\n",
            "Text: A masterpiece. The director did an incredible job.\n",
            "Sentiment: Positive\n",
            "Polarity: 0.9, Subjectivity: 0.9\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Sample movie reviews\n",
        "movie_reviews = [\n",
        "    \"The movie was fantastic! The plot was gripping and the characters were well-developed.\",\n",
        "    \"I didn't like the movie at all. It was too slow and the acting was poor.\",\n",
        "    \"It was an average movie, nothing special but not bad either.\",\n",
        "    \"Absolutely terrible! I wasted two hours of my life.\",\n",
        "    \"A masterpiece. The director did an incredible job.\",\n",
        "]\n",
        "\n",
        "# Function to analyze sentiment using TextBlob\n",
        "def analyze_sentiment(reviews):\n",
        "    results = []\n",
        "    for review in reviews:\n",
        "        blob = TextBlob(review)\n",
        "        sentiment = blob.sentiment\n",
        "        sentiment_label = 'Positive' if sentiment.polarity > 0 else 'Negative' if sentiment.polarity < 0 else 'Neutral'\n",
        "        results.append({\n",
        "            'review': review,\n",
        "            'polarity': sentiment.polarity,\n",
        "            'subjectivity': sentiment.subjectivity,\n",
        "            'sentiment': sentiment_label\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Analyzing sentiment\n",
        "sentiment_results = analyze_sentiment(movie_reviews)\n",
        "\n",
        "# Displaying the results\n",
        "for i, result in enumerate(sentiment_results):\n",
        "    print(f\"Review {i+1}:\")\n",
        "    print(f\"Text: {result['review']}\")\n",
        "    print(f\"Sentiment: {result['sentiment']}\")\n",
        "    print(f\"Polarity: {result['polarity']}, Subjectivity: {result['subjectivity']}\")\n",
        "    print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install pandas\n",
        "!pip install scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z0zZJjsBCRe",
        "outputId": "623a37e6-1ca6-4e89-82d2-07e7c1996f59"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Downloading required NLTK data\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initializing VADER sentiment analyzer, stop words, and lemmatizer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Converting text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Removing HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Removing URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Removing punctuation and special characters\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Removing stop words and lemmatize tokens\n",
        "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Joining tokens back into a single string\n",
        "    cleaned_text = ' '.join(cleaned_tokens)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "def analyze_sentiment(review):\n",
        "    # Preprocessing the review text\n",
        "    cleaned_review = preprocess_text(review)\n",
        "\n",
        "    # Analyzing the sentiment of the cleaned review\n",
        "    sentiment = sia.polarity_scores(cleaned_review)\n",
        "\n",
        "    # Determining sentiment as positive, negative, or neutral\n",
        "    if sentiment['compound'] >= 0.05:\n",
        "        return \"Positive\"\n",
        "    elif sentiment['compound'] <= -0.05:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Sample movie reviews\n",
        "reviews = [\n",
        "    \"I absolutely loved this movie! The acting was brilliant and the storyline was captivating.\",\n",
        "    \"The movie was okay, but it lacked the depth I was hoping for.\",\n",
        "    \"I hated this movie. It was a complete waste of time.\",\n",
        "    \"It was a decent movie, but nothing spectacular.\",\n",
        "    \"One of the best movies I've seen in a long time!\"\n",
        "]\n",
        "\n",
        "# Creating a DataFrame to store reviews and their sentiments\n",
        "df = pd.DataFrame(reviews, columns=['Review'])\n",
        "df['Sentiment'] = df['Review'].apply(analyze_sentiment)\n",
        "\n",
        "# Displaying the results\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18KZAsKkBDCC",
        "outputId": "779b52bb-faf6-45ea-8448-e14c4e4a5c39"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review Sentiment\n",
            "0  I absolutely loved this movie! The acting was ...  Positive\n",
            "1  The movie was okay, but it lacked the depth I ...  Positive\n",
            "2  I hated this movie. It was a complete waste of...  Negative\n",
            "3    It was a decent movie, but nothing spectacular.   Neutral\n",
            "4   One of the best movies I've seen in a long time!  Positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Detailed Preprocessing Steps:**\n",
        "\n",
        "* Lowercasing: Converts all characters in the text to lowercase to ensure uniformity.\n",
        "\n",
        "\n",
        "* Removing HTML Tags: Strips out any HTML tags that may be present in the review text using regular expressions.\n",
        "\n",
        "\n",
        "* Removing URLs: Cleans out any URLs that may be present using a regular expression pattern.\n",
        "\n",
        "* Removing Punctuation and Special Characters: This step removes all non-alphabetic characters, including punctuation, numbers, and special symbols.\n",
        "\n",
        "* Tokenization: Splits the text into individual words (tokens), which allows for more granular processing.\n",
        "\n",
        "* Stop Word Removal: Removes common English words that do not contribute to the sentiment of the text (like \"the,\" \"is,\" \"in,\" etc.), which helps focus on the more meaningful words.\n",
        "\n",
        "* Lemmatization: Reduces words to their base or root form (e.g., \"running\" to \"run\"), which helps in grouping similar words and reducing noise.\n",
        "\n",
        "* Joining Tokens: The cleaned tokens are joined back into a single string after preprocessing to make them ready for sentiment analysis.\n",
        "\n",
        "* Sentiment Analysis:\n",
        "After preprocessing, the cleaned text is passed to the VADER sentiment analyzer.\n",
        "The analyzer computes sentiment scores and determines whether the review is positive, negative, or neutral based on the compound score.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Output:\n",
        "The program displays the original reviews along with their calculated sentiments in a DataFrame. This approach helps ensure that the sentiment analysis is based on cleaned and normalized data, leading to more accurate results.\n",
        "\n",
        "\n",
        "This detailed preprocessing pipeline is crucial for handling real-time data, especially if the input text is noisy or unstructured. It can be adapted and extended for more complex scenarios, such as analyzing reviews in different languages or dealing with domain-specific terminology."
      ],
      "metadata": {
        "id": "DPCY2ZlXBkJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using Hugging Face Transformers for Sentiment Analysis**"
      ],
      "metadata": {
        "id": "7z6nAZGhKFMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk2APYwlJhDq",
        "outputId": "46e4a265-e0d9-42fa-80b6-c1d093f225c9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initializing the sentiment analysis pipeline\n",
        "sentiment_analyzer = pipeline('sentiment-analysis')\n",
        "\n",
        "def analyze_sentiment(review):\n",
        "    # Using the AI model to predict sentiment\n",
        "    result = sentiment_analyzer(review)[0]\n",
        "\n",
        "    # Extracting sentiment label and score\n",
        "    sentiment = result['label']\n",
        "    score = result['score']\n",
        "\n",
        "    return sentiment, score\n",
        "\n",
        "# Sampling movie reviews\n",
        "reviews = [\n",
        "    \"I absolutely loved this movie! The acting was brilliant and the storyline was captivating.\",\n",
        "    \"The movie was okay, but it lacked the depth I was hoping for.\",\n",
        "    \"I hated this movie. It was a complete waste of time.\",\n",
        "    \"It was a decent movie, but nothing spectacular.\",\n",
        "    \"One of the best movies I've seen in a long time!\"\n",
        "]\n",
        "\n",
        "# Analyzing sentiment for each review\n",
        "for review in reviews:\n",
        "    sentiment, score = analyze_sentiment(review)\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"Sentiment: {sentiment} (Score: {score:.2f})\")\n",
        "    print(\"----\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwIzJCCCJk_Z",
        "outputId": "9cb00991-c0e3-4fc4-b1ed-7156f2a60a73"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: I absolutely loved this movie! The acting was brilliant and the storyline was captivating.\n",
            "Sentiment: POSITIVE (Score: 1.00)\n",
            "----\n",
            "Review: The movie was okay, but it lacked the depth I was hoping for.\n",
            "Sentiment: NEGATIVE (Score: 1.00)\n",
            "----\n",
            "Review: I hated this movie. It was a complete waste of time.\n",
            "Sentiment: NEGATIVE (Score: 1.00)\n",
            "----\n",
            "Review: It was a decent movie, but nothing spectacular.\n",
            "Sentiment: NEGATIVE (Score: 0.99)\n",
            "----\n",
            "Review: One of the best movies I've seen in a long time!\n",
            "Sentiment: POSITIVE (Score: 1.00)\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "Hugging Face Pipeline:\n",
        "\n",
        "The pipeline function provides an easy-to-use interface for various NLP tasks, including sentiment analysis.\n",
        "\n",
        "By default, it uses a pre-trained model such as distilbert-base-uncased-finetuned-sst-2-english, which is a distilled version of BERT fine-tuned on the SST-2 dataset for sentiment classification.\n",
        "Sentiment Prediction:\n",
        "\n",
        "The AI model outputs a label (either \"POSITIVE\" or \"NEGATIVE\") and a score (confidence level for the prediction).\n",
        "The score indicates how confident the model is about its prediction.\n",
        "Sample Output:\n",
        "\n",
        "Each review is analyzed, and the sentiment along with the confidence score is printed."
      ],
      "metadata": {
        "id": "sK8xM9ZqJzGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azure-ai-textanalytics==5.2.0"
      ],
      "metadata": {
        "id": "r-OPVEqTIxoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This requires environment variables named \"LANGUAGE_KEY\" and \"LANGUAGE_ENDPOINT\"\n",
        "language_key = os.environ.get('LANGUAGE_KEY')\n",
        "language_endpoint = os.environ.get('LANGUAGE_ENDPOINT')\n",
        "\n",
        "from azure.ai.textanalytics import TextAnalyticsClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "# Authenticating the client using the key and endpoint\n",
        "def authenticate_client():\n",
        "    ta_credential = AzureKeyCredential(language_key)\n",
        "    text_analytics_client = TextAnalyticsClient(\n",
        "            endpoint=language_endpoint,\n",
        "            credential=ta_credential)\n",
        "    return text_analytics_client\n",
        "\n",
        "client = authenticate_client()\n",
        "\n",
        "# Example method for detecting sentiment and opinions in text\n",
        "def sentiment_analysis_with_opinion_mining_example(client):\n",
        "\n",
        "    documents = [\n",
        "        \"The food and service were unacceptable. The concierge was nice, however.\"\n",
        "    ]\n",
        "\n",
        "    result = client.analyze_sentiment(documents, show_opinion_mining=True)\n",
        "    doc_result = [doc for doc in result if not doc.is_error]\n",
        "\n",
        "    positive_reviews = [doc for doc in doc_result if doc.sentiment == \"positive\"]\n",
        "    negative_reviews = [doc for doc in doc_result if doc.sentiment == \"negative\"]\n",
        "\n",
        "    positive_mined_opinions = []\n",
        "    mixed_mined_opinions = []\n",
        "    negative_mined_opinions = []\n",
        "\n",
        "    for document in doc_result:\n",
        "        print(\"Document Sentiment: {}\".format(document.sentiment))\n",
        "        print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
        "            document.confidence_scores.positive,\n",
        "            document.confidence_scores.neutral,\n",
        "            document.confidence_scores.negative,\n",
        "        ))\n",
        "        for sentence in document.sentences:\n",
        "            print(\"Sentence: {}\".format(sentence.text))\n",
        "            print(\"Sentence sentiment: {}\".format(sentence.sentiment))\n",
        "            print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
        "                sentence.confidence_scores.positive,\n",
        "                sentence.confidence_scores.neutral,\n",
        "                sentence.confidence_scores.negative,\n",
        "            ))\n",
        "            for mined_opinion in sentence.mined_opinions:\n",
        "                target = mined_opinion.target\n",
        "                print(\"......'{}' target '{}'\".format(target.sentiment, target.text))\n",
        "                print(\"......Target score:\\n......Positive={0:.2f}\\n......Negative={1:.2f}\\n\".format(\n",
        "                    target.confidence_scores.positive,\n",
        "                    target.confidence_scores.negative,\n",
        "                ))\n",
        "                for assessment in mined_opinion.assessments:\n",
        "                    print(\"......'{}' assessment '{}'\".format(assessment.sentiment, assessment.text))\n",
        "                    print(\"......Assessment score:\\n......Positive={0:.2f}\\n......Negative={1:.2f}\\n\".format(\n",
        "                        assessment.confidence_scores.positive,\n",
        "                        assessment.confidence_scores.negative,\n",
        "                    ))\n",
        "            print(\"\\n\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "sentiment_analysis_with_opinion_mining_example(client)"
      ],
      "metadata": {
        "id": "mNq68duRImIM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}